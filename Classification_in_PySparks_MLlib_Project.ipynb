{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in PySpark's MLlib Project Solution\n",
    "\n",
    "### Genre classification\n",
    "Now it's time to leverage what we learned in the lectures to a REAL classification project! Have you ever wondered what makes us, humans, able to tell apart two songs of different genres? How we do we inherenly know the difference between a pop song and heavy metal? This type of classifcation may seem easy for us, but it's a very difficult challenge for a computer to do. So the question is, could an automatic genre classifcation model be possible? \n",
    "\n",
    "For this project we will be classifying songs based on a number of characteristics into a set of 23 electronic genres. This technology could be used by an application like Pandora to recommend songs to users or just create meaningful channels. Super fun!\n",
    "\n",
    "### Dataset\n",
    "*beatsdataset.csv*\n",
    "Each row is an electronic music song. The dataset contains 100 song for each genre among 23 electronic music genres, they were the top (100) songs of their genres on November 2016. The 71 columns are audio features extracted of a two random minutes sample of the file audio. These features have been extracted using pyAudioAnalysis (https://github.com/tyiannak/pyAudioAnalysis).\n",
    "\n",
    "### Your task\n",
    "Create an algorithm that classifies songs into the 23 genres provided. Test out several different models and select the highest performing one. Also play around with feature selection methods and finally try to make a recommendation to a user.  \n",
    "\n",
    "For the feature selection aspect of this project, you may need to get a bit creative if you want to select features from a non-tree algorithm. I did not go over this aspect of PySpark intentionally in the previous lectures to give you chance to get used to researching the PySpark documentation page. Here is the link to the Feature Selectors section of the documentation that just might come in handy: https://spark.apache.org/docs/latest/ml-features.html#feature-selectors\n",
    "\n",
    "Good luck! Have fun :)\n",
    "\n",
    "### Source\n",
    "https://www.kaggle.com/caparrini/beatsdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in functions we will need\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.29.100:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f851bf0b130>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's create our PySpark instance\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"Classification\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark\n",
    "# Click the hyperlinked \"Spark UI\" link to view details about your Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"\"\n",
    "df = spark.read.csv(path+'beatsdataset.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>1-ZCRm</th>\n",
       "      <th>2-Energym</th>\n",
       "      <th>3-EnergyEntropym</th>\n",
       "      <th>4-SpectralCentroidm</th>\n",
       "      <th>5-SpectralSpreadm</th>\n",
       "      <th>6-SpectralEntropym</th>\n",
       "      <th>7-SpectralFluxm</th>\n",
       "      <th>8-SpectralRolloffm</th>\n",
       "      <th>9-MFCCs1m</th>\n",
       "      <th>...</th>\n",
       "      <th>63-ChromaVector8std</th>\n",
       "      <th>64-ChromaVector9std</th>\n",
       "      <th>65-ChromaVector10std</th>\n",
       "      <th>66-ChromaVector11std</th>\n",
       "      <th>67-ChromaVector12std</th>\n",
       "      <th>68-ChromaDeviationstd</th>\n",
       "      <th>69-BPM</th>\n",
       "      <th>70-BPMconf</th>\n",
       "      <th>71-BPMessentia</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.136440</td>\n",
       "      <td>0.088861</td>\n",
       "      <td>3.201201</td>\n",
       "      <td>0.262825</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>1.114423</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.256682</td>\n",
       "      <td>-22.723259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.132792</td>\n",
       "      <td>128.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.117039</td>\n",
       "      <td>0.108389</td>\n",
       "      <td>3.194001</td>\n",
       "      <td>0.247657</td>\n",
       "      <td>0.250288</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>-21.775871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.112767</td>\n",
       "      <td>126.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.128525</td>\n",
       "      <td>3.123837</td>\n",
       "      <td>0.217205</td>\n",
       "      <td>0.228652</td>\n",
       "      <td>0.789647</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.156822</td>\n",
       "      <td>-22.472722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.022201</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.123373</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.103050</td>\n",
       "      <td>0.167042</td>\n",
       "      <td>3.150830</td>\n",
       "      <td>0.233593</td>\n",
       "      <td>0.245032</td>\n",
       "      <td>0.967082</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>0.168083</td>\n",
       "      <td>-21.470751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.151730</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>3.194498</td>\n",
       "      <td>0.293730</td>\n",
       "      <td>0.267231</td>\n",
       "      <td>1.353005</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>-21.371157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.190708</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.127047</td>\n",
       "      <td>0.153488</td>\n",
       "      <td>3.221987</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>0.257361</td>\n",
       "      <td>1.090034</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.230099</td>\n",
       "      <td>-21.234846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.019479</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.168933</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0    1-ZCRm  2-Energym  3-EnergyEntropym  4-SpectralCentroidm  \\\n",
       "0    0  0.136440   0.088861          3.201201             0.262825   \n",
       "1    1  0.117039   0.108389          3.194001             0.247657   \n",
       "2    2  0.085308   0.128525          3.123837             0.217205   \n",
       "3    3  0.103050   0.167042          3.150830             0.233593   \n",
       "4    4  0.151730   0.148405          3.194498             0.293730   \n",
       "5    5  0.127047   0.153488          3.221987             0.261693   \n",
       "\n",
       "   5-SpectralSpreadm  6-SpectralEntropym  7-SpectralFluxm  8-SpectralRolloffm  \\\n",
       "0           0.249212            1.114423         0.007003            0.256682   \n",
       "1           0.250288            1.065668         0.005387            0.199821   \n",
       "2           0.228652            0.789647         0.008247            0.156822   \n",
       "3           0.245032            0.967082         0.006571            0.168083   \n",
       "4           0.267231            1.353005         0.003872            0.292055   \n",
       "5           0.257361            1.090034         0.004943            0.230099   \n",
       "\n",
       "   9-MFCCs1m  ...  63-ChromaVector8std  64-ChromaVector9std  \\\n",
       "0 -22.723259  ...             0.003431             0.004981   \n",
       "1 -21.775871  ...             0.004461             0.006441   \n",
       "2 -22.472722  ...             0.001529             0.004556   \n",
       "3 -21.470751  ...             0.001591             0.003514   \n",
       "4 -21.371157  ...             0.003945             0.004131   \n",
       "5 -21.234846  ...             0.002986             0.006533   \n",
       "\n",
       "   65-ChromaVector10std  66-ChromaVector11std  67-ChromaVector12std  \\\n",
       "0              0.010818              0.024001              0.005201   \n",
       "1              0.007469              0.015499              0.005589   \n",
       "2              0.007723              0.017482              0.002901   \n",
       "3              0.009477              0.023162              0.004165   \n",
       "4              0.011330              0.028188              0.002639   \n",
       "5              0.010347              0.025008              0.003035   \n",
       "\n",
       "   68-ChromaDeviationstd      69-BPM  70-BPMconf  71-BPMessentia    class  \n",
       "0               0.015056  133.333333    0.132792           128.0  BigRoom  \n",
       "1               0.019339  120.000000    0.112767           126.0  BigRoom  \n",
       "2               0.022201  133.333333    0.123373           129.0  BigRoom  \n",
       "3               0.015379  133.333333    0.158876           129.0  BigRoom  \n",
       "4               0.019079  133.333333    0.190708           129.0  BigRoom  \n",
       "5               0.019479  133.333333    0.168933           129.0  BigRoom  \n",
       "\n",
       "[6 rows x 73 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- 1-ZCRm: double (nullable = true)\n",
      " |-- 2-Energym: double (nullable = true)\n",
      " |-- 3-EnergyEntropym: double (nullable = true)\n",
      " |-- 4-SpectralCentroidm: double (nullable = true)\n",
      " |-- 5-SpectralSpreadm: double (nullable = true)\n",
      " |-- 6-SpectralEntropym: double (nullable = true)\n",
      " |-- 7-SpectralFluxm: double (nullable = true)\n",
      " |-- 8-SpectralRolloffm: double (nullable = true)\n",
      " |-- 9-MFCCs1m: double (nullable = true)\n",
      " |-- 10-MFCCs2m: double (nullable = true)\n",
      " |-- 11-MFCCs3m: double (nullable = true)\n",
      " |-- 12-MFCCs4m: double (nullable = true)\n",
      " |-- 13-MFCCs5m: double (nullable = true)\n",
      " |-- 14-MFCCs6m: double (nullable = true)\n",
      " |-- 15-MFCCs7m: double (nullable = true)\n",
      " |-- 16-MFCCs8m: double (nullable = true)\n",
      " |-- 17-MFCCs9m: double (nullable = true)\n",
      " |-- 18-MFCCs10m: double (nullable = true)\n",
      " |-- 19-MFCCs11m: double (nullable = true)\n",
      " |-- 20-MFCCs12m: double (nullable = true)\n",
      " |-- 21-MFCCs13m: double (nullable = true)\n",
      " |-- 22-ChromaVector1m: double (nullable = true)\n",
      " |-- 23-ChromaVector2m: double (nullable = true)\n",
      " |-- 24-ChromaVector3m: double (nullable = true)\n",
      " |-- 25-ChromaVector4m: double (nullable = true)\n",
      " |-- 26-ChromaVector5m: double (nullable = true)\n",
      " |-- 27-ChromaVector6m: double (nullable = true)\n",
      " |-- 28-ChromaVector7m: double (nullable = true)\n",
      " |-- 29-ChromaVector8m: double (nullable = true)\n",
      " |-- 30-ChromaVector9m: double (nullable = true)\n",
      " |-- 31-ChromaVector10m: double (nullable = true)\n",
      " |-- 32-ChromaVector11m: double (nullable = true)\n",
      " |-- 33-ChromaVector12m: double (nullable = true)\n",
      " |-- 34-ChromaDeviationm: double (nullable = true)\n",
      " |-- 35-ZCRstd: double (nullable = true)\n",
      " |-- 36-Energystd: double (nullable = true)\n",
      " |-- 37-EnergyEntropystd: double (nullable = true)\n",
      " |-- 38-SpectralCentroidstd: double (nullable = true)\n",
      " |-- 39-SpectralSpreadstd: double (nullable = true)\n",
      " |-- 40-SpectralEntropystd: double (nullable = true)\n",
      " |-- 41-SpectralFluxstd: double (nullable = true)\n",
      " |-- 42-SpectralRolloffstd: double (nullable = true)\n",
      " |-- 43-MFCCs1std: double (nullable = true)\n",
      " |-- 44-MFCCs2std: double (nullable = true)\n",
      " |-- 45-MFCCs3std: double (nullable = true)\n",
      " |-- 46-MFCCs4std: double (nullable = true)\n",
      " |-- 47-MFCCs5std: double (nullable = true)\n",
      " |-- 48-MFCCs6std: double (nullable = true)\n",
      " |-- 49-MFCCs7std: double (nullable = true)\n",
      " |-- 50-MFCCs8std: double (nullable = true)\n",
      " |-- 51-MFCCs9std: double (nullable = true)\n",
      " |-- 52-MFCCs10std: double (nullable = true)\n",
      " |-- 53-MFCCs11std: double (nullable = true)\n",
      " |-- 54-MFCCs12std: double (nullable = true)\n",
      " |-- 55-MFCCs13std: double (nullable = true)\n",
      " |-- 56-ChromaVector1std: double (nullable = true)\n",
      " |-- 57-ChromaVector2std: double (nullable = true)\n",
      " |-- 58-ChromaVector3std: double (nullable = true)\n",
      " |-- 59-ChromaVector4std: double (nullable = true)\n",
      " |-- 60-ChromaVector5std: double (nullable = true)\n",
      " |-- 61-ChromaVector6std: double (nullable = true)\n",
      " |-- 62-ChromaVector7std: double (nullable = true)\n",
      " |-- 63-ChromaVector8std: double (nullable = true)\n",
      " |-- 64-ChromaVector9std: double (nullable = true)\n",
      " |-- 65-ChromaVector10std: double (nullable = true)\n",
      " |-- 66-ChromaVector11std: double (nullable = true)\n",
      " |-- 67-ChromaVector12std: double (nullable = true)\n",
      " |-- 68-ChromaDeviationstd: double (nullable = true)\n",
      " |-- 69-BPM: double (nullable = true)\n",
      " |-- 70-BPMconf: double (nullable = true)\n",
      " |-- 71-BPMessentia: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               class|count|\n",
      "+--------------------+-----+\n",
      "|           PsyTrance|  100|\n",
      "|           HardDance|  100|\n",
      "|              Breaks|  100|\n",
      "|  HardcoreHardTechno|  100|\n",
      "|   IndieDanceNuDisco|  100|\n",
      "|              Trance|  100|\n",
      "|           DeepHouse|  100|\n",
      "|ElectronicaDowntempo|  100|\n",
      "|           ReggaeDub|  100|\n",
      "|             Minimal|  100|\n",
      "|         DrumAndBass|  100|\n",
      "|             Dubstep|  100|\n",
      "|             BigRoom|  100|\n",
      "|              Techno|  100|\n",
      "|               House|  100|\n",
      "|         FutureHouse|  100|\n",
      "|        ElectroHouse|  100|\n",
      "|           GlitchHop|  100|\n",
      "|           TechHouse|  100|\n",
      "|              HipHop|  100|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = df.columns # Collect the column names as a list\n",
    "input_columns = input_columns[1:-1] # keep only relevant columns: from column 1 to \n",
    "\n",
    "dependent_var = 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label (class variable) to string type to prep for reindexing\n",
    "# Pyspark is expecting a zero indexed integer for the label column. \n",
    "# Just in case our data is not in that format... we will treat it by using the StringIndexer built in method\n",
    "renamed = df.withColumn(\"label_str\", df[dependent_var].cast(StringType())) #Rename and change to string type\n",
    "indexer = StringIndexer(inputCol=\"label_str\", outputCol=\"label\") #Pyspark is expecting the this naming convention \n",
    "indexed = indexer.fit(renamed).transform(renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all string type data in the input column list to numeric\n",
    "# Otherwise the Algorithm will not be able to process it\n",
    "\n",
    "# Also we will use these lists later on\n",
    "numeric_inputs = []\n",
    "string_inputs = []\n",
    "for column in input_columns:\n",
    "    # First identify the string vars in your input column list\n",
    "    if str(indexed.schema[column].dataType) == 'StringType':\n",
    "        # Set up your String Indexer function\n",
    "        indexer = StringIndexer(inputCol=column, outputCol=column+\"_num\") \n",
    "        # Then call on the indexer you created here\n",
    "        indexed = indexer.fit(indexed).transform(indexed)\n",
    "        # Rename the column to a new name so you can disinguish it from the original\n",
    "        new_col_name = column+\"_num\"\n",
    "        # Add the new column name to the string inputs list\n",
    "        string_inputs.append(new_col_name)\n",
    "    else:\n",
    "        # If no change was needed, take no action \n",
    "        # And add the numeric var to the num list\n",
    "        numeric_inputs.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1-ZCRm',\n",
       "  '2-Energym',\n",
       "  '3-EnergyEntropym',\n",
       "  '4-SpectralCentroidm',\n",
       "  '5-SpectralSpreadm',\n",
       "  '6-SpectralEntropym',\n",
       "  '7-SpectralFluxm',\n",
       "  '8-SpectralRolloffm',\n",
       "  '9-MFCCs1m',\n",
       "  '10-MFCCs2m',\n",
       "  '11-MFCCs3m',\n",
       "  '12-MFCCs4m',\n",
       "  '13-MFCCs5m',\n",
       "  '14-MFCCs6m',\n",
       "  '15-MFCCs7m',\n",
       "  '16-MFCCs8m',\n",
       "  '17-MFCCs9m',\n",
       "  '18-MFCCs10m',\n",
       "  '19-MFCCs11m',\n",
       "  '20-MFCCs12m',\n",
       "  '21-MFCCs13m',\n",
       "  '22-ChromaVector1m',\n",
       "  '23-ChromaVector2m',\n",
       "  '24-ChromaVector3m',\n",
       "  '25-ChromaVector4m',\n",
       "  '26-ChromaVector5m',\n",
       "  '27-ChromaVector6m',\n",
       "  '28-ChromaVector7m',\n",
       "  '29-ChromaVector8m',\n",
       "  '30-ChromaVector9m',\n",
       "  '31-ChromaVector10m',\n",
       "  '32-ChromaVector11m',\n",
       "  '33-ChromaVector12m',\n",
       "  '34-ChromaDeviationm',\n",
       "  '35-ZCRstd',\n",
       "  '36-Energystd',\n",
       "  '37-EnergyEntropystd',\n",
       "  '38-SpectralCentroidstd',\n",
       "  '39-SpectralSpreadstd',\n",
       "  '40-SpectralEntropystd',\n",
       "  '41-SpectralFluxstd',\n",
       "  '42-SpectralRolloffstd',\n",
       "  '43-MFCCs1std',\n",
       "  '44-MFCCs2std',\n",
       "  '45-MFCCs3std',\n",
       "  '46-MFCCs4std',\n",
       "  '47-MFCCs5std',\n",
       "  '48-MFCCs6std',\n",
       "  '49-MFCCs7std',\n",
       "  '50-MFCCs8std',\n",
       "  '51-MFCCs9std',\n",
       "  '52-MFCCs10std',\n",
       "  '53-MFCCs11std',\n",
       "  '54-MFCCs12std',\n",
       "  '55-MFCCs13std',\n",
       "  '56-ChromaVector1std',\n",
       "  '57-ChromaVector2std',\n",
       "  '58-ChromaVector3std',\n",
       "  '59-ChromaVector4std',\n",
       "  '60-ChromaVector5std',\n",
       "  '61-ChromaVector6std',\n",
       "  '62-ChromaVector7std',\n",
       "  '63-ChromaVector8std',\n",
       "  '64-ChromaVector9std',\n",
       "  '65-ChromaVector10std',\n",
       "  '66-ChromaVector11std',\n",
       "  '67-ChromaVector12std',\n",
       "  '68-ChromaDeviationstd',\n",
       "  '69-BPM',\n",
       "  '70-BPMconf',\n",
       "  '71-BPMessentia'],\n",
       " [])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs,string_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-SpectralFluxm has been treated for positive (right) skewness. (skew =) 1.6396138160129063 )\n",
      "22-ChromaVector1m has been treated for positive (right) skewness. (skew =) 2.4162415204309258 )\n",
      "23-ChromaVector2m has been treated for positive (right) skewness. (skew =) 4.154796693680583 )\n",
      "24-ChromaVector3m has been treated for positive (right) skewness. (skew =) 1.1974019617504328 )\n",
      "25-ChromaVector4m has been treated for positive (right) skewness. (skew =) 2.446635863594906 )\n",
      "26-ChromaVector5m has been treated for positive (right) skewness. (skew =) 2.154482876187508 )\n",
      "27-ChromaVector6m has been treated for positive (right) skewness. (skew =) 2.01234064472543 )\n",
      "28-ChromaVector7m has been treated for positive (right) skewness. (skew =) 1.1829228989215521 )\n",
      "29-ChromaVector8m has been treated for positive (right) skewness. (skew =) 3.7372643733999955 )\n",
      "30-ChromaVector9m has been treated for positive (right) skewness. (skew =) 2.4117416421548645 )\n",
      "31-ChromaVector10m has been treated for positive (right) skewness. (skew =) 2.1979538518563233 )\n",
      "32-ChromaVector11m has been treated for positive (right) skewness. (skew =) 2.1924295373960554 )\n",
      "33-ChromaVector12m has been treated for positive (right) skewness. (skew =) 2.278981912155668 )\n",
      "41-SpectralFluxstd has been treated for positive (right) skewness. (skew =) 1.8577721462401056 )\n",
      "56-ChromaVector1std has been treated for positive (right) skewness. (skew =) 1.9111935514138085 )\n",
      "57-ChromaVector2std has been treated for positive (right) skewness. (skew =) 2.9078740765487394 )\n",
      "59-ChromaVector4std has been treated for positive (right) skewness. (skew =) 2.9677243313898827 )\n",
      "60-ChromaVector5std has been treated for positive (right) skewness. (skew =) 2.3681450229993315 )\n",
      "61-ChromaVector6std has been treated for positive (right) skewness. (skew =) 2.3950817653605396 )\n",
      "63-ChromaVector8std has been treated for positive (right) skewness. (skew =) 2.801578595136121 )\n",
      "64-ChromaVector9std has been treated for positive (right) skewness. (skew =) 1.7779798465610313 )\n",
      "65-ChromaVector10std has been treated for positive (right) skewness. (skew =) 1.9944501757850421 )\n",
      "66-ChromaVector11std has been treated for positive (right) skewness. (skew =) 1.1835182964170816 )\n",
      "67-ChromaVector12std has been treated for positive (right) skewness. (skew =) 2.087086908618814 )\n",
      "69-BPM has been treated for positive (right) skewness. (skew =) 2.9547734198613234 )\n",
      "70-BPMconf has been treated for positive (right) skewness. (skew =) 1.0889332324135428 )\n"
     ]
    }
   ],
   "source": [
    "# Treat for skewness\n",
    "# Flooring and capping\n",
    "# Plus if right skew take the log +1\n",
    "# if left skew do exp transformation\n",
    "# This is best practice\n",
    "\n",
    "# create empty dictionary d\n",
    "d = {}\n",
    "# Create a dictionary of quantiles from your numeric cols\n",
    "# I'm doing the top and bottom 1% but you can adjust if needed\n",
    "for col in numeric_inputs: \n",
    "    d[col] = indexed.approxQuantile(col,[0.01,0.99],0.25) #if you want to make it go faster increase the last number\n",
    "\n",
    "#Now check for skewness for all numeric cols\n",
    "for col in numeric_inputs:\n",
    "    skew = indexed.agg(skewness(indexed[col])).collect() #check for skewness\n",
    "    skew = skew[0][0]\n",
    "    # If skewness is found,\n",
    "    # This function will make the appropriate corrections\n",
    "    if skew > 1: # If right skew, floor, cap and log(x+1)\n",
    "        indexed = indexed.withColumn(col, \\\n",
    "        log(when(df[col] < d[col][0],d[col][0])\\\n",
    "        .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "        .otherwise(indexed[col] ) +1).alias(col))\n",
    "        print(col+\" has been treated for positive (right) skewness. (skew =)\",skew,\")\")\n",
    "    elif skew < -1: # If left skew floor, cap and exp(x)\n",
    "        indexed = indexed.withColumn(col, \\\n",
    "        exp(when(df[col] < d[col][0],d[col][0])\\\n",
    "        .when(indexed[col] > d[col][1], d[col][1])\\\n",
    "        .otherwise(indexed[col] )).alias(col))\n",
    "        print(col+\" has been treated for negative (left) skewness. (skew =\",skew,\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\n"
     ]
    }
   ],
   "source": [
    "# Now check for negative values in the dataframe. \n",
    "# Produce a warning if there are negative values in the dataframe that Naive Bayes cannot be used. \n",
    "# Note: we only need to check the numeric input values since anything that is indexed won't have negative values\n",
    "\n",
    "# Calculate the mins for all columns in the df\n",
    "minimums = df.select([min(c).alias(c) for c in df.columns if c in numeric_inputs]) \n",
    "# Create an array for all mins and select only the input cols\n",
    "min_array = minimums.select(array(numeric_inputs).alias(\"mins\")) \n",
    "# Collect golobal min as Python object\n",
    "df_minimum = min_array.select(array_min(min_array.mins)).collect() \n",
    "# Slice to get the number itself\n",
    "df_minimum = df_minimum[0][0] \n",
    "\n",
    "# If there are ANY negative vals found in the df, print a warning message\n",
    "if df_minimum < 0:\n",
    "    print(\"WARNING: The Naive Bayes Classifier will not be able to process your dataframe as it contains negative values\")\n",
    "else:\n",
    "    print(\"No negative values were found in your dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>1-ZCRm</th>\n",
       "      <th>2-Energym</th>\n",
       "      <th>3-EnergyEntropym</th>\n",
       "      <th>4-SpectralCentroidm</th>\n",
       "      <th>5-SpectralSpreadm</th>\n",
       "      <th>6-SpectralEntropym</th>\n",
       "      <th>7-SpectralFluxm</th>\n",
       "      <th>8-SpectralRolloffm</th>\n",
       "      <th>9-MFCCs1m</th>\n",
       "      <th>...</th>\n",
       "      <th>63-ChromaVector8std</th>\n",
       "      <th>64-ChromaVector9std</th>\n",
       "      <th>65-ChromaVector10std</th>\n",
       "      <th>66-ChromaVector11std</th>\n",
       "      <th>67-ChromaVector12std</th>\n",
       "      <th>68-ChromaDeviationstd</th>\n",
       "      <th>69-BPM</th>\n",
       "      <th>70-BPMconf</th>\n",
       "      <th>71-BPMessentia</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.136440</td>\n",
       "      <td>0.088861</td>\n",
       "      <td>3.201201</td>\n",
       "      <td>0.262825</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>1.114423</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.256682</td>\n",
       "      <td>-22.723259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003431</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.015056</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.132792</td>\n",
       "      <td>128.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.117039</td>\n",
       "      <td>0.108389</td>\n",
       "      <td>3.194001</td>\n",
       "      <td>0.247657</td>\n",
       "      <td>0.250288</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>-21.775871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.112767</td>\n",
       "      <td>126.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.128525</td>\n",
       "      <td>3.123837</td>\n",
       "      <td>0.217205</td>\n",
       "      <td>0.228652</td>\n",
       "      <td>0.789647</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.156822</td>\n",
       "      <td>-22.472722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.022201</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.123373</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.103050</td>\n",
       "      <td>0.167042</td>\n",
       "      <td>3.150830</td>\n",
       "      <td>0.233593</td>\n",
       "      <td>0.245032</td>\n",
       "      <td>0.967082</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>0.168083</td>\n",
       "      <td>-21.470751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.158876</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.151730</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>3.194498</td>\n",
       "      <td>0.293730</td>\n",
       "      <td>0.267231</td>\n",
       "      <td>1.353005</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.292055</td>\n",
       "      <td>-21.371157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.190708</td>\n",
       "      <td>129.0</td>\n",
       "      <td>BigRoom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0    1-ZCRm  2-Energym  3-EnergyEntropym  4-SpectralCentroidm  \\\n",
       "0    0  0.136440   0.088861          3.201201             0.262825   \n",
       "1    1  0.117039   0.108389          3.194001             0.247657   \n",
       "2    2  0.085308   0.128525          3.123837             0.217205   \n",
       "3    3  0.103050   0.167042          3.150830             0.233593   \n",
       "4    4  0.151730   0.148405          3.194498             0.293730   \n",
       "\n",
       "   5-SpectralSpreadm  6-SpectralEntropym  7-SpectralFluxm  8-SpectralRolloffm  \\\n",
       "0           0.249212            1.114423         0.007003            0.256682   \n",
       "1           0.250288            1.065668         0.005387            0.199821   \n",
       "2           0.228652            0.789647         0.008247            0.156822   \n",
       "3           0.245032            0.967082         0.006571            0.168083   \n",
       "4           0.267231            1.353005         0.003872            0.292055   \n",
       "\n",
       "   9-MFCCs1m  ...  63-ChromaVector8std  64-ChromaVector9std  \\\n",
       "0 -22.723259  ...             0.003431             0.004981   \n",
       "1 -21.775871  ...             0.004461             0.006441   \n",
       "2 -22.472722  ...             0.001529             0.004556   \n",
       "3 -21.470751  ...             0.001591             0.003514   \n",
       "4 -21.371157  ...             0.003945             0.004131   \n",
       "\n",
       "   65-ChromaVector10std  66-ChromaVector11std  67-ChromaVector12std  \\\n",
       "0              0.010818              0.024001              0.005201   \n",
       "1              0.007469              0.015499              0.005589   \n",
       "2              0.007723              0.017482              0.002901   \n",
       "3              0.009477              0.023162              0.004165   \n",
       "4              0.011330              0.028188              0.002639   \n",
       "\n",
       "   68-ChromaDeviationstd      69-BPM  70-BPMconf  71-BPMessentia    class  \n",
       "0               0.015056  133.333333    0.132792           128.0  BigRoom  \n",
       "1               0.019339  120.000000    0.112767           126.0  BigRoom  \n",
       "2               0.022201  133.333333    0.123373           129.0  BigRoom  \n",
       "3               0.015379  133.333333    0.158876           129.0  BigRoom  \n",
       "4               0.019079  133.333333    0.190708           129.0  BigRoom  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we correct for negative values that may have been found above, \n",
    "# We need to vectorize our df\n",
    "# becauase the function that we use to make that correction requires a vector. \n",
    "# Now create your final features list\n",
    "features_list = numeric_inputs + string_inputs\n",
    "# Create your vector assembler object\n",
    "assembler = VectorAssembler(inputCols=features_list,outputCol='features')\n",
    "# And call on the vector assembler to transform your dataframe\n",
    "output = assembler.transform(indexed).select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled to range: [0.000000, 1000.000000]\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[519.818266700239...|\n",
      "|  0.0|[435.295463992565...|\n",
      "|  0.0|[297.057129121742...|\n",
      "|  0.0|[374.352647734368...|\n",
      "|  0.0|[586.432337466259...|\n",
      "|  0.0|[478.897323979332...|\n",
      "|  0.0|[462.989461602348...|\n",
      "|  0.0|[535.448873531282...|\n",
      "|  0.0|[437.894973202184...|\n",
      "|  0.0|[524.003195633498...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the mix max scaler object \n",
    "# This is what will correct for negative values\n",
    "# I like to use a high range like 1,000 \n",
    "#     because I only see one decimal place in the final_data.show() call\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",min=0,max=1000)\n",
    "print(\"Features scaled to range: [%f, %f]\" % (scaler.getMin(), scaler.getMax()))\n",
    "\n",
    "# Compute summary statistics and generate MinMaxScalerModel\n",
    "scalerModel = scaler.fit(output)\n",
    "\n",
    "# rescale each feature to range [min, max].\n",
    "scaled_data = scalerModel.transform(output)\n",
    "final_data = scaled_data.select('label','scaledFeatures')\n",
    "# Rename to default value\n",
    "final_data = final_data.withColumnRenamed(\"scaledFeatures\",\"features\")\n",
    "final_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = final_data.randomSplit([0.7,0.3])\n",
    "seed = 40\n",
    "train_val = 0.7\n",
    "test_val = 1-train_val\n",
    "train,test = final_data.randomSplit([train_val,test_val],seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in dependencies\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Mlflow libaries\n",
    "import mlflow\n",
    "from mlflow import spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment\n",
    "# This will actually automatically create one if the one you call on doesn't exist\n",
    "mlflow.set_experiment(experiment_name = \"Experiment-3\")\n",
    "\n",
    "# set up your client\n",
    "from  mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a run and attach it to the experiment you just created\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "\n",
    "experiment_name = \"Experiment-3\"\n",
    "def create_run(experiment_name):\n",
    "    mlflow.set_experiment(experiment_name = experiment_name)\n",
    "    for x in experiments:\n",
    "        if experiment_name in x.name:\n",
    "#             print(experiment_name)\n",
    "#             print(x)\n",
    "            experiment_index = experiments.index(x)\n",
    "            run = client.create_run(experiments[experiment_index].experiment_id) # returns mlflow.entities.Run\n",
    "#             print(run)\n",
    "            return run\n",
    "\n",
    "# Example run command\n",
    "# run = create_run('Experiment-3')\n",
    "# run = create_run(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the functionality here\n",
    "run = create_run('Experiment-3')\n",
    "#dummy run\n",
    "# Add tag to a run\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", \"Gradient Boosted Tree\")\n",
    "client.set_tag(run.info.run_id,\"Random Seed\",908)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",0.7)\n",
    "\n",
    "# Add params and metrics to a run\n",
    "client.log_param(run.info.run_id, \"Max Depth\", 90)\n",
    "client.log_param(run.info.run_id, \"Max Bins\", 50)\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", 0.87)\n",
    "\n",
    "# Terminate the client\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our evaluation objects\n",
    "Bin_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction') #labelCol='label'\n",
    "# Bin_evaluator = BinaryClassificationEvaluator() #labelCol='label'\n",
    "MC_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\") # redictionCol=\"prediction\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-0.02149608036230148,0.06823021549273668,0.05089599626183121,-0.016015264794603617,0.0012217647520220431,-0.12228572510856088,0.03143508246725725,-0.032106564938455574,0.08702223045752905,-0.12904354673129048,0.061869293594756646,0.039890675771671755,0.14360464619554844,-0.047599785262046564,-0.0025730922846182096,0.023672537191425,-0.10930463816432477,-0.1338061036542189,0.01679906966017987,-0.06403816986208058,0.025181359666381558,0.05413847311922635,0.07430762653193526]\n",
      "Coefficients: \n",
      "DenseMatrix([[ 4.55588959e-04,  1.53307412e-03,  1.65412860e-03, ...,\n",
      "              -1.59910181e-03, -6.90430408e-04,  1.56058217e-03],\n",
      "             [-2.15195846e-04, -1.57164476e-04,  2.75060835e-04, ...,\n",
      "               3.25830421e-03, -2.55229466e-03,  2.12409079e-03],\n",
      "             [-3.93704164e-04,  1.08456676e-04,  7.70871582e-04, ...,\n",
      "              -2.32575574e-03,  3.75468755e-04, -1.02683565e-03],\n",
      "             ...,\n",
      "             [ 4.52395004e-04, -8.01739208e-04, -3.05974317e-04, ...,\n",
      "              -1.62962203e-03,  7.83321024e-04,  1.03680648e-03],\n",
      "             [ 7.78144402e-05, -1.30462592e-04, -6.62368805e-04, ...,\n",
      "              -1.41314249e-03,  8.80537550e-04,  1.12786192e-03],\n",
      "             [ 1.01108296e-03, -1.21686922e-03,  2.60505068e-03, ...,\n",
      "              -4.23079144e-04,  1.00168358e-03,  1.59887570e-03]])\n",
      "39.79135618479881\n"
     ]
    }
   ],
   "source": [
    "run = create_run(experiment_name)\n",
    "\n",
    "# This method uses cross validation and allows for hyperparamter tuning via grid searching\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Set up your parameter grid for the cross validator to consudt hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "                             .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "             .addGrid(classifier.maxIter, [10, 15,20])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect the best model and\n",
    "# print the coefficient matrix\n",
    "# These values should be compared relative to eachother\n",
    "# And intercepts can be prepared to other models\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Intercept: \" + str(BestModel.interceptVector))\n",
    "print(\"Coefficients: \\n\" + str(BestModel.coefficientMatrix))\n",
    "\n",
    "# Generate predictions\n",
    "# fitModel automatically uses the best model \n",
    "# so we don't need to use BestModel here\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "# Now print the accuract rate of the model or AUC for a binary classifier\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)\n",
    "\n",
    "########### Track results in MLflow UI ################\n",
    "\n",
    "# Add tag to a run\n",
    "# Extract the name of the classifier\n",
    "classifier_name = type(classifier).__name__\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "\n",
    "# Log Model (can't do this to the client)\n",
    "# mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# Extract params of Best Model\n",
    "paramMap = BestModel.extractParamMap()\n",
    "\n",
    "# Log parameters to the client\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxIter' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Iter\", val)\n",
    "for key, val in paramMap.items():\n",
    "    if 'regParam' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Reg Param\", val)\n",
    "\n",
    "# Log metrics to the client\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# Set a runs status to finished (best practice)\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mIntercept: \u001b[0m -5.799228550714 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.00046422849831339024,0.0014960355186393627,0.0016556173009855955,-0.00010322012542998654,0.002117418074172022,0.0004247642395075349,-0.00161574817649254,-0.0007420628071019194,0.003946614922006337,-0.0012653790174592167,0.0009990519028971268,0.000620048491703367,0.0004771564362796456,-0.00022591170701251524,-0.0006667181560669461,-0.00046685391533160547,-0.00033093758380358003,0.001699209804796262,-0.0004462067255278849,0.0003426139610700278,-0.0006551523032293889,0.0019559062847088055,-0.0031141214024889173,0.0010637453418667331,-0.0005468095962605253,0.00040272265009407975,0.00030860851326417875,-0.0018647785215210075,-0.0024745624932917608,-5.35247445527883e-05,-0.0005670793646301597,-0.0003613121336033365,0.0008151687974082931,-0.0017394895997368766,-0.0020748250337786996,9.329814708464934e-05,1.6448349224507564e-05,-0.002297848255141204,-0.0012770854350293455,0.0005579136862624061,0.00015280078489437088,-0.0007092490254572009,0.0024693228869605605,-0.0024604159896532375,-0.0019441644929091252,0.0004269042322744688,0.0006718140426534957,-0.0010634425375731246,-4.650026334392517e-05,0.00041857901678649687,0.00011099791601672776,0.001097491520467248,0.0011011619756474756,0.0014533271237946524,-0.001453397064115119,-0.0001954703746424696,-0.0007704765124077406,0.0009419221556173649,-0.0012690043520890385,-0.000830659673608883,-0.0015295002205287463,0.0003784313760371654,0.0015821476223211802,0.000292663044698742,0.00011854578113718915,-0.0009153425276541991,0.0007462155409499708,-0.00031576841024489786,-0.004362885372394056,-0.0019597656391574167,0.0023946045252095146]\n",
      "\u001b[1mIntercept: \u001b[0m -2.592162166401442 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0013507200489285315,-0.0007471387397747547,0.0012750595021695317,0.00012834631912908987,0.0020374450862872943,-0.0004861864665091863,-0.0015534273736770021,-0.0009022240813287111,-0.0011214472302441452,0.00011994847833780513,0.0005675929198743551,-0.0004282855273776876,-0.0002860072492750311,-0.0013273299959269615,-0.0005310835774481181,0.0005315370881812742,-0.0023730837357342056,-0.0012170689304761286,-0.0014913120221068856,-0.0007964810187020671,-0.00029251573127331125,-0.001074321048337848,-0.0015034721649931154,0.0013846135313009037,-0.0020504267044082697,-0.0019646266735805144,-0.00018103878907273904,0.0015847373661571932,0.00035210292917114933,-0.00015460887195381046,-0.0005197329701983944,0.0001271419939809327,-0.0016256716959743586,0.0015183196705266183,-0.0009018190740347256,-0.0013903298395399526,-0.000966963374323105,-0.0002763705960608754,-0.0014192209514470374,0.002519430461201395,-0.001113095386581224,0.0011718611207332176,0.0007176524860884623,0.002782361440651311,0.0010699776352311177,0.0012102306980553829,-0.0005498719643175544,0.00021544066531882486,0.002497652291232012,-0.0013094072011849028,0.0004018794802345254,0.0005481563273429114,-0.0007565576738103896,0.0005176602680652321,-5.16630692097003e-05,-0.00204439400786455,0.0006195051138631574,-0.0010555856153590273,-0.0024900246872610514,-0.0011761276731181486,0.0001988185495781352,-0.00031477640027094265,-0.0014476058455833675,6.015138367240854e-06,0.0006582071879333889,0.0002346186857569983,-0.0012049481039849781,0.0004543152621720723,0.002686369235929548,-0.004805906259060638,0.004663367238462535]\n",
      "\u001b[1mIntercept: \u001b[0m -6.973138152658177 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0003501500835768543,-0.0007190503780662038,0.003105917885821744,-0.0011639727130828973,0.0005407945186834602,-0.00035478058565200087,-0.002150296345517193,-0.0008961010903611612,0.0015398141110860605,0.0013890933082031942,-0.00048712952865202856,0.002767162114443462,-0.001022589590039806,-0.0005687113071037781,-0.002739199251814311,0.0008124477014577145,0.001835754016282875,-0.0015051131653496287,0.00023258720364065878,-0.0006140756199672842,-0.0004962013010601165,0.0016097649926415372,-0.0002518573936703652,-0.0005287387692651925,0.00022302040793133394,0.0007938261762428826,-0.00033497599773393735,0.0002581061376738802,0.0003920724961426805,6.787095410248231e-05,0.0006348110690887058,9.850904387474532e-06,-0.0002717087330539637,-0.0010132719185922915,0.0005848131028916286,0.0022285427919034226,-0.0022718783268707693,0.0010333707441430812,0.0008602581393523238,0.0010315070274469456,-0.0003020598420010509,0.0008515594321918955,-8.864196814170781e-05,0.0008180691207275329,0.0010657739732584653,-7.51846472363851e-05,-0.0010615304513010675,-0.0008109910179688623,-0.00043039598581364846,0.0005686465424210704,0.0016234867335849017,0.0022001523035098973,0.0001544893482894707,0.0004998429075921544,0.0016372170655804329,-0.0016173227020353767,0.0009597204732052356,6.891290274025534e-05,-0.0005609971227790054,0.0010248908698319448,-0.0006480911705760089,-4.8521790311331737e-05,0.002414869858820317,0.00011091115251172158,-0.00242487581678577,-0.001334301936358038,0.0010313294380058966,-0.0005053982490232895,-0.0031241675963366885,0.0002190116008424875,-0.001202373834872733]\n",
      "\u001b[1mIntercept: \u001b[0m -2.2871066289780337 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0013252068968627206,-0.003407143462088892,0.0006372400218123659,-0.0013355214683831978,-0.0001250256836230118,-0.0012280650388265867,-0.0013558805643673216,-0.0010477428272243463,-0.0033758892494420594,0.0021419025702760406,0.0014517544895749283,0.0004361373663539866,-0.002872410555472059,-0.00024589992166931536,-0.0004937564623146638,0.0012502589952633454,-0.0022389384201271633,2.729422047759717e-05,-0.0014084975566561536,0.0004360000891542466,0.0006327897891266734,0.001230262492292506,0.0007899161737668303,0.0009277639056021083,-0.00034441048007483375,0.0011336693499968528,0.0012949863905238257,0.0002761657421765642,0.004658199214058196,0.00019282214566818727,-0.0006851865372293883,0.0010044094500203504,0.002042047787952274,0.0011916662697454997,0.0010917904315537969,0.0026568168696557734,-0.001099891056049622,0.002445697591263722,6.598612384098342e-05,0.0004905579199737096,-6.337816065659286e-05,0.0005693637270199464,-0.0017563056599471218,-0.0011960272630313713,-0.0011510539073405813,0.0004665711750750847,-0.00012464462396750089,-0.001179890822535066,-0.0005296113929929543,0.00011052606514486208,-0.00146227232926222,-0.0007107817227964321,0.0025466412953577275,0.0008116753599752904,0.00025575093500196047,-0.0005588287427461263,0.0006917870242517323,0.0010830051791419512,-0.0007236012741590135,0.001147285233404858,-0.0002623501664585698,-0.0005769250346017408,0.0010296606972621347,0.0009966886032283448,0.000361567169916274,-0.0008254578351548973,0.0011647963952849387,0.00046645517497108597,-0.0025064088702381614,0.0016478776588372815,0.0013114805094204664]\n",
      "\u001b[1mIntercept: \u001b[0m -3.079175739598994 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0006895906547728446,0.003930818578762358,-0.0003110722619549127,0.001862026823862954,0.0037478810815227575,-0.0008810494294777373,-0.0002515472079600229,-0.0012348531128305133,0.0015146589719786335,0.0017550221211282586,0.0015675806905371514,-0.0005075124018833305,-0.0007292784817127585,0.0011521266275341573,-0.000793273582534745,-0.0013356235129026834,0.0006192939047344378,-0.0014925918863928998,-0.0009604069627113745,0.0009362713454649094,-0.00028433334060977596,-0.00019252871862413513,0.0013216318068427994,0.001471918301540114,-0.000523191345669326,0.000949938779088125,-0.00176733288736939,-0.0002826641725443552,-0.001650383055799973,-0.0001828106751903711,-0.0013200217171793344,-0.00017100312359921054,0.0003306766980113635,0.00046117245950167617,-9.602546738639058e-05,-0.0008975148853481306,-0.0004177005407675661,-0.00017778918462111291,-0.0020930469429351834,0.0016489286664902118,-0.0021671257188210545,0.0020395651713092503,0.0030457149782985343,0.000907397940730858,-0.0019475872838937154,-0.0010842669718599345,0.0009840572627300298,0.0009111591941696493,-0.000585250387122328,0.00023686442974663223,-0.0004968471171405478,-0.0023736095473845652,-0.0017046706579415454,-0.00034188265676020845,-0.00026197311502156674,-0.0008719753952778366,-0.0005484256605250144,-0.0002927732382254472,0.002686981610773902,0.001722406261988496,-0.0001880376860549184,-0.002330957763063627,-0.0004473033643264329,4.9750418260302826e-05,-0.0007233688769135722,0.0009908741492461925,-0.0001896320118692187,-0.0005767094619256028,0.0019395049216924375,-0.001963693029025845,-0.007248893811881535]\n",
      "\u001b[1mIntercept: \u001b[0m -8.40930453590869 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.00043374427788884395,0.0009405433019968379,0.0015204102578230683,0.001189232275141935,-0.0004102363449384374,0.00039342569821062623,-0.0022567685171492376,0.0014045036984144117,-0.001251549774352708,-0.0024049818532164173,-0.0007886146253891702,0.00030612231320099875,0.0035010443096191455,-0.001035041681760067,-0.0007608637688586008,0.001590406141128706,0.0006406295935262146,-0.0001740077113300256,-0.0002025499814077235,0.0008774538145170641,0.0005282644024196609,-0.0008093607017398129,-0.00017446890085047277,0.0024153578116759187,0.0014547675230921358,-0.001224421259822637,0.0009650046900721187,-0.00042777167284394166,0.001903374525351345,5.1058570369113246e-06,0.0011397363653609686,-0.001657186371546273,0.00046360332076826735,0.00297433508631734,0.0012489141951481891,0.0013276706675637538,-0.001914890892447595,-0.002957668839165989,-0.0016423930462346787,0.000649655510906561,-0.0004150773982298512,0.0003490749715250643,-0.0007787253363285119,0.0014195045726141083,0.002431141100235263,-0.0006252985103532441,0.001195597923601975,-0.0004024721383406107,-2.315874350101587e-05,0.00021398449530150984,0.0007104630654313542,0.00020987374598439152,0.0007385248054213263,-0.0012020341047946964,-0.0010977497831478316,-0.0009231211640220709,-0.0006857584826157201,0.0002970700066727368,0.0004949775574638356,-0.0019764740810002805,-0.00012218873537418778,-0.0005977977790017968,-0.0006709576766611756,-0.00033629994396286813,0.0018863299294593007,-0.0023420759949039074,-0.00037257109306219053,0.0010856166365051942,0.0034972547206592883,-0.0032548543217000726,-0.0013692455935842205]\n",
      "\u001b[1mIntercept: \u001b[0m -5.409873122465161 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.00017714062112746609,0.0012616934407522014,0.0013216301187567686,-2.4280109084411258e-05,3.926159610182662e-05,0.0008037604277147249,-0.002206281491356974,-0.0004071442098499975,0.004545810043652881,-0.0019778546836000015,0.001790272714633155,0.0011694405440336455,-0.0010047087380305468,-0.0019171554833530217,-3.9792767436308656e-05,0.0004992790446534176,-0.0009480045930260161,0.00112349562544667,0.0009083818008518244,-0.0012200559673261457,-0.0013755520735354975,0.0022432245899297737,-0.0021525214040700423,0.00010656178466661766,0.0007048388353542503,-0.001651716266797201,-0.00044911975094410437,-0.00021649710206620763,0.0007315831772758136,0.0004488598740522318,0.0004709351379004606,-0.0005674170047490427,-0.001445274848667486,-0.0015427494746824333,-0.00039101602684179967,0.0008600938358957441,0.00100983455550814,-0.00010752340380750381,-0.0008296126244186038,-1.5248974760998357e-05,-0.0005686209764121302,-0.0008367117299615208,0.002973652427592816,0.0003328132572143161,-0.00031172184786051394,0.00146772561371994,-0.00013651552348944591,-0.0008642377736988677,-0.0008276809383673078,0.0008344199390417783,0.001363184020446233,-0.0003283368760355514,0.0010964900457141663,-0.0004954961941914138,-0.0018119193992251195,-0.0007165226567754514,0.001034196102192208,0.00044827882168216413,-0.00211327262639671,-0.0007052538743720513,0.00017546203523145472,0.0006022694118639121,-0.0015624448522614024,-9.678691189765357e-05,-0.001657153266575904,-0.001763001421962106,-0.0004864669365202041,0.00024591918690566395,-0.0019392648029255414,-0.0033278354435216785,0.002973603345112897]\n",
      "\u001b[1mIntercept: \u001b[0m 6.245161744042011 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0012076115376559093,-0.0035751973477192015,-0.0005114032332591837,-0.0012477655459696751,-0.0005515076469686099,-0.0007804328732458393,-0.002693856867522568,-0.0007451840090684658,-0.001663296574015262,0.001034473721332334,0.0006296040245410557,-0.0012659654501351563,-0.0014373966533484646,-0.00037415379043406093,-0.0010129851763869182,0.00013667818785262646,-0.0015395516966939396,0.001087944749751678,0.001035459203382586,-0.0017399468678339339,-0.002734248722082622,-0.0018146483385550873,0.002084199524703617,-0.0005712992714588116,0.001256804555591986,0.001175120766303652,-0.0006187352122019212,-6.840066407691617e-05,-0.001680461725191865,0.0008773097394363948,7.592335641255566e-05,0.0017282804683555163,0.0007907297776095813,0.00019717997176897935,-0.0009112454923154498,0.0009039062168377805,0.0011688343864477866,-0.00011389446732003158,0.0007936064048346064,-0.0004908138249429477,0.0006749366079213806,-0.0012850073280522623,-0.00027255069053432545,0.001452858105335217,-0.0014250612205478031,-0.00045761482955257915,-0.0007639646073110848,0.001851336363117133,-0.0005681319866087446,-0.000309184146595277,0.00013224145435362786,0.0007424930594132766,-0.00032170752651611626,0.0009418019432201039,0.0001495698575978579,-0.0003459879189929828,-0.0009648796493170494,-0.0018457241561241912,-0.0017068534197586813,-0.001253009819706103,0.0003161044814252143,0.0008690051365304816,-0.003912022009894847,-0.0014750154211002273,-0.0014250743235618981,-0.0005892458302293736,-0.0013705342866512677,0.0009337523627896276,0.0006565091622438164,-0.0009234342971223164,-0.0018659458675402564]\n",
      "\u001b[1mIntercept: \u001b[0m -8.516965956576273 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.0008546283910174206,-0.004048033683698184,-0.002048774548269604,-0.0009429503004027328,0.00036296996143619,0.0003125456203940595,-0.0024828423658460573,-0.0009257206629935679,0.0005135132374940385,0.0013207252156003286,0.002344825066988806,0.0015539953372672045,0.0009182378418041345,-0.0002710966355805529,-0.0009245178203029965,-0.00036777281530010536,0.0029754315221357536,-7.573031824853055e-05,0.0017765379262407305,-0.00020703063739402648,-0.0005353919325900631,0.0012405631946508747,-0.0021270608219196396,-0.0031078453999680883,-0.001035258774695068,0.0019849591321123177,-0.0014429087957660972,-0.0009571549893212657,-0.0017870472454578092,-0.0018100023761657834,0.0006455534040182581,0.0009413128999989082,-0.0014984678261282306,-0.005234084865981337,0.0001273624791881016,0.0005904492493656749,0.00010243187875326205,-0.0006681722374798852,0.0002589852202565492,0.0019862531992518332,-0.00304001242264708,0.0003549272036699109,0.0003347268034746005,-0.0010081081216584383,-0.0004942184849286678,0.0011717595721176587,-0.002197005809615088,0.0019529930457354106,0.0011548448513716927,0.0014724420589482953,0.0009217553830058536,0.00022318184589787974,-8.656852630451046e-05,0.0004334446996852002,0.0016867513604111456,0.0008221424661307858,0.0016434526934379261,0.00098739284500655,0.00020212988059073223,0.0017531577161497799,-0.00044708682920328196,0.0020064584431482256,0.002346023632658944,0.002178383047015199,0.0013582771079350164,0.0002622840551411832,0.0010299988075997456,0.002071025655598735,-0.0008593541519680123,-0.0015274914265771206,-0.00020645071034690977]\n",
      "\u001b[1mIntercept: \u001b[0m -5.5032181282396335 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.00036226873181745175,0.000847934909629349,0.00415290400883973,-0.0006281758161268392,-0.0013026106540507758,-0.00017026398852918397,-0.0014402675319105417,-0.0004142736971580772,0.004003595437368137,-0.0007154338796937929,-0.0011138176036807476,-0.0005858228227009926,-0.0009979823894141204,-0.0014529199163826913,-0.002051038330165299,0.00017381656552845577,-0.0001484471144410787,-0.0005251446131138859,-0.0003010669632192991,0.0002371299712586364,-0.0013324851955813838,-0.0005842751810936944,0.0008541245629808263,-0.0014463704641017692,0.00010420340761162268,1.8713779666172688e-06,-0.00040450179846815513,0.0003864741177234302,-7.54439843408597e-05,-0.0003687925383714304,-0.0010163759732200617,0.0005796301164338076,-0.0012857017974237167,-0.001218329324781755,0.0003777265821161381,0.001939324170134216,-0.0010037327129825678,0.0012068978469104402,0.00022060599774807914,0.0009487733617660185,0.001454846648821635,0.0012823992390485492,0.0016321862985415885,-0.0001837138566988669,-0.0005308968504257169,-0.0004595164296228664,-0.0009565297364235373,-0.0010696889675226458,0.0004831234379787322,-0.0009584185446005509,-0.0006042728101346913,-0.0002565120915573634,0.00015637669239948183,0.0011013771930617978,0.0018055407780506732,-0.0012236845490403462,0.001076116564350543,0.0014391183878662635,0.00030329101873634827,0.001770888328914333,0.001501304552656972,0.001886116420391509,0.00039976140267060074,0.0005630449123181502,-0.001458979525627268,-0.0012149055939624663,0.0016207106584542976,-0.0006928749549278369,-0.0032895293274272644,-0.0016407307599891814,0.0024245090458428487]\n",
      "\u001b[1mIntercept: \u001b[0m -3.4709124933019475 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.000350032057873467,-0.0009717663432780839,-0.00045520518623861587,-0.0003366592380191913,-0.0002786333214194791,0.00031860665140481754,-0.0009647058686912726,-0.0010573251371887248,0.002800902263146961,-0.0018173885012939689,0.00024935746860501576,-0.0007628610781666349,0.0001179732128823447,-0.000919777970983092,0.00046230995111396346,-0.0002490871409253622,-0.00012157381310110733,0.0016726205737102957,-0.0002244461487043728,-0.002659181374305326,0.0010119678054520355,-0.001073863367676298,-0.00012163741894922937,0.00016974045812992387,-0.0010803251071736862,0.0006934480688756113,0.0006015381784166938,0.000596191051081073,-0.001045890583288587,-0.0004293735152568597,-0.00027602407332223564,0.0004406054608650194,-0.0018025453955585475,-0.00012591289200969337,0.000759607140133954,-0.000755117514046874,-0.000591368250501533,0.0003223153734948314,0.0005780320856835244,0.0008818444849269729,0.0023224135930458257,0.00013313736797853566,0.0007046080196051641,-0.0012870570169699555,0.0010447732284189493,-0.000798421136137497,0.0006569301043716939,0.0010024035019325043,0.0009039096400609253,0.0016413172316822031,-0.0008428015378791339,0.0010907260022326032,0.0005430249103530013,-0.0003837891326996908,-0.0004233711629104687,0.005058989623997447,7.223004447077552e-05,0.0008179611325069522,0.00011881821377010329,-0.000307489622820666,-0.00013152798092231784,0.0013907376067694905,-0.0017808562050412354,-0.0006006039441205558,0.0003704683291926788,0.0002726965052230703,-0.0005713880743414018,-0.0008227844138544802,0.0011195675612988725,-0.00526287413806107,-0.0030030228644271732]\n",
      "\u001b[1mIntercept: \u001b[0m -7.780390525730451 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.0006788552288942613,0.001982636248883696,0.0015725423477258348,0.00026297969775680865,0.0012134206375915522,0.0002207377479841658,-0.0009136340599980071,0.0001685044628799814,0.0018987812497747178,0.0006614532301022803,-0.0021846185833574007,-0.0014412326012497236,0.0020065728321453486,0.0015951535319607855,0.0007615797778206063,0.00024103145081846885,-0.0015591809612585021,0.0006927062053199523,-0.001435202381526333,-0.0022420335377035224,-0.0012903591033467433,-0.000992708740486091,-0.001105487634999403,-0.0006937224079384723,0.000763588311555736,-0.00014878694539496734,-0.001287953824397518,0.0009168770669963892,-0.000516264500956289,-0.0014012757038558761,0.00012024672281161971,-0.0010347610389764945,-0.0005523339830649594,-0.0007625395538004321,0.0002653796985513363,-0.0027088002430617503,-0.0010560574919898484,-0.001560032932543879,-0.002283830063011195,-0.0011747654854720264,-0.0018723905279424034,-0.0011699929348980463,-0.002606768149892076,-0.001271766599494365,3.5974093100004924e-05,0.0015684967838667972,0.000557129304393238,0.0012613820569756641,0.0007013944135792406,-0.0005779975949962656,0.00029140464568447886,0.0016591929062022876,0.0001744828040752778,-0.0003107508892954739,-0.00025048502235982764,-0.0010307360474498576,-0.0010331662702943907,0.001000233505633989,0.0009687509941470172,-0.0016816075893345943,0.00033500130514505915,-9.523830090895529e-05,0.003143683693751996,0.00031084975780650324,0.0002961218222135675,-0.0018912560647045742,0.0014569796560781037,0.0020670678765500735,0.0024844123411544568,0.0062751211458020525,0.00179909124340274]\n",
      "\u001b[1mIntercept: \u001b[0m 6.834566368243771 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.0018826416440114219,0.003392795555673206,-0.0019700906227471766,0.0003036037529591751,-0.0008309632448614087,-0.0003173367763113531,0.0029879566518463225,0.0004329809336790243,-0.0028597312521067898,-0.0015004943819899464,-0.00018269178560826498,9.922754621745801e-05,0.003359548867928881,-0.0003483919172341271,0.0008388545220611261,-0.0018787683574030265,-0.0014506132198335835,-0.00045249329291019343,0.0008896394084013563,-0.0013422689040700703,0.0015187751402375607,-0.0014038213469969485,-0.00032037454819922636,0.00017914652966704642,-0.001395903511722428,-0.002602201800062346,-0.001233561227320062,0.0013022682307956834,-0.0005039084045417302,0.0007131486702177491,-0.001227157359364811,-0.002545518550412697,-3.470543592679581e-05,-0.0013456970066929176,-0.00017540027861295953,-0.001913266300008387,-0.0008895447576738815,0.001603658900277339,5.006459450198087e-05,-0.0017353099129102656,-0.0030814920439789333,-0.0014372867479827047,-0.0019209958782528745,0.0011644853373434091,0.002271108241354733,-0.0005324043868782639,-0.0009785445145478774,-0.0026543575394008603,-0.0007960007109478948,-0.0008328365073148496,-0.001554550977633578,-0.002135111667155787,-0.0011256270874941807,-0.0012008704527606408,-0.0018161919648120664,0.0005482394386753836,-0.0008925902325138893,-0.00041824732255278153,-0.0014137067916953822,-0.001022803963440924,-0.0006333223735100834,0.00021768019980741358,-0.002617971410509646,-0.0016999561058803126,-0.0008743210395607956,0.0005955107841520707,-0.0007430628931538565,-0.004840807575792766,-0.001958136736779054,0.0030779091025154594,0.0006666480772242041]\n",
      "\u001b[1mIntercept: \u001b[0m -6.260460146327826 \u001b[1m\n",
      "Coefficients:\u001b[0m [4.507346480059041e-05,0.0009019526486134281,0.002630414668809941,-0.0001614585887676809,-0.0015937127890335656,0.0008349947513187026,-0.0018981513393007158,-0.00015631169850680135,-0.0010645313418961005,-0.00276185707160547,2.5148711135566118e-05,-0.0018042788706960165,0.0004763070246829637,0.0008514753751698928,0.0010717748349509826,-0.000385684652074511,-0.00015645356854043248,0.0022703923038686256,-0.0004543812847773106,-0.0005788842791209686,-0.00045400727089621955,-0.0006333883332676161,-0.0020687487699950586,0.0008278881332606969,-0.0015933590326563836,0.0005499344013524014,0.0032516056878227036,-0.0016728685757847516,0.0011153379580564418,0.0011514646153933954,0.0004712321232552156,-0.0017704916806843352,-0.0005428181328848529,0.001037502093852269,-0.0017793003717855775,0.0028743136747749988,-0.0012464764765101985,3.558651759729897e-05,0.0002771110353001292,8.721058421790021e-05,-0.001553845790856739,-0.0008281003912053603,-0.001937438137509896,0.003209670754970095,-0.0004373757087702776,0.000731572128729208,0.00014363711400223756,0.0016919556143218841,0.0002710580639537998,-0.0009763948009993203,-0.0008254498648777477,0.0011165901001732623,-3.4465447434470065e-06,0.002153196519011213,0.00320168903840457,-0.0008326238509441568,-0.0013094434325631094,0.0001954544183142831,-0.0025169240569316823,0.0004999001480258269,-0.002204098894381981,-0.0004711783115554609,0.00207752369372125,-0.0010326765674890852,0.0001631945431437847,0.00016224232935553695,0.0001077953616653555,-0.0012703150267163454,0.0031967494680264293,-0.0014676642315950158,-0.001336983132487703]\n",
      "\u001b[1mIntercept: \u001b[0m -5.555168125991396 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.0004772413942774625,-0.0006074902889658879,0.0004470709952954895,-0.0006677878351473814,-0.0015646612659519282,7.57738676819787e-07,-0.0008552022613492875,-0.00025560040780824646,0.0006664765538965995,0.000547351835910271,0.0028390600049617134,-0.0006128883301217013,2.0900888055720306e-05,0.0012869134845306615,0.00013486938474954125,-0.002543547133450466,0.0008847648042574766,-0.0004007229461142147,0.000769387298189516,0.0014294668343440232,-0.0007901071755365194,-0.0009662266012443896,-0.0005091117499672724,-0.00031719968462846633,0.0002848399769855986,0.0006106079770416847,-0.0006768513798231006,0.0006959578111744098,-0.002940041364239455,-0.0011997855943580778,-0.0010454435099679737,-0.0011384677132289227,-0.0010313463000316712,-0.001258986423369319,0.0017582554749977811,0.0003278061761180992,-0.001300285770619839,0.0014430209632938773,-0.0012148057675733836,0.0013712403923858269,-0.0012858257584700838,0.0007327126385072446,0.0011181298725909472,0.00040240073278696725,-0.000978791158037008,0.0018699621874983313,-0.00020861568091196832,-0.0020120579486303477,-0.0002245248584035886,0.0002185390798289671,1.6135653029840297e-05,-1.8809774395261816e-05,0.0012194415924109633,0.0014190847843376197,0.0012781315699747975,-0.0005018993587280583,0.0019366503541759328,0.0005140394096142368,0.0010114966889157272,0.0012202949898190182,-0.0006282639000189876,0.00014453943078213336,0.0026623928223163873,0.001596079271448126,-0.000409885184787787,-0.0007113588357096049,4.733137158976447e-05,-0.0012391385851463405,-0.005839413809275947,0.00014598083378230793,0.0023148101993071745]\n",
      "\u001b[1mIntercept: \u001b[0m -5.697277124462721 \u001b[1m\n",
      "Coefficients:\u001b[0m [5.348098592933023e-06,-0.0052530956634212105,-0.0020773431662317503,-0.0006521107243676598,0.0006135259685221659,-0.001005464357228246,-0.0025658275453775345,-0.0013689465737277025,0.0006679932086205868,0.00022312824803554342,0.0017507357484851562,0.0001909521464225242,-0.00013935557401429716,0.0011035053320175659,0.00047877267926401887,0.0017990210799910997,-0.0003897136516093752,0.0005346452332987695,0.0006711821689517178,0.0004963796959558465,-0.0005534091297404521,0.0010639529854301302,0.0006832527780712216,-0.0016809437379666822,-8.300950528039218e-05,-0.0003922754784791832,-0.0014660998148516566,-0.0007206354543894917,0.0011738980215225423,0.0022703614796878414,7.0388858927322106e-06,0.0014404903985767703,0.0017078276370103792,-0.0013982856964671238,-0.00010096822744080234,0.00286571831530529,0.0023198311451363956,-0.0010579991774847762,0.0017747956756275361,0.00032760432267580356,-0.0023925964957975587,-0.00044522261349641995,0.0007140360796119608,-0.0017011061424812633,0.0006911851946214622,-0.0031235177704370446,0.0007336434126904909,0.0001575248615955748,0.002050657109553224,-0.0010897573090755596,0.00030561029000740453,0.00036715417938863254,0.0010172100789152482,0.001078061665125514,-0.0011648543778047255,-0.0010809463681758346,-0.0007183690056397752,0.0019061998751273355,-0.002263301130213758,0.00200110522247029,0.0007527165752952258,-0.0002957806421949493,0.00034257899602557946,0.0010135726791559573,0.0003268799542707498,0.0004715059487272114,-0.0015348416700463683,0.0018456977407292363,-0.0011147809513700909,0.000701794642040995,0.0006008185570294376]\n",
      "\u001b[1mIntercept: \u001b[0m -2.5795085475674098 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0010335615700764666,0.0007290460048106928,-0.0007812397135532067,-0.0006440350991404305,-0.0016743471946271571,-0.0005418041833210677,0.0025526793026196173,-7.383260486286218e-05,-0.0014530007721567104,0.0011698862892006315,3.335410582687576e-05,-0.000406378581816103,0.0007363723439513829,-0.0006539216843581731,-0.0007170503126215987,-0.0014860380473088988,0.00016925827521947583,-0.0014014479236732795,-0.00028234114837467255,0.0019855700745991804,0.0019979827111430725,3.867817699243705e-05,0.00046787817363422524,-0.0011198162454001393,0.0007093038999905323,-0.0005290998002037441,0.0017358002786678137,0.0015081248678658528,0.00023399454771524605,0.0003648120770524953,0.000708965328924863,0.0001854315140125478,0.000677937194657556,0.00039185656260615686,-0.00030436848611842504,-0.0018847018682790532,0.001122159776617869,0.0014896513685147587,0.0014782305835304445,0.0008412041376196346,0.003817528557279523,0.0004648967946817993,0.002891423204594159,0.0009776626492291913,0.0004375080333028745,0.00033691403163609246,0.0016279812087782234,-0.0003694439245312658,0.0007469140842989105,-0.0001640637748486426,-0.0005781712219263622,-0.0016795170735067484,-0.00038189359059720375,-0.002479888711624098,-0.003049825679689405,-0.000543634272099836,0.00047568502884160873,0.0007070069560118715,0.0005737547096690058,-0.0007176966952392466,-0.0023706059271732627,0.000442163449146661,-0.002010749846400188,-7.648420663919315e-05,-0.00036761033303647376,0.0005319461806180331,-0.00019807094742146442,-0.002007901181736201,-0.002258761763619563,-0.0017444681034003361,0.0021025693498721867]\n",
      "\u001b[1mIntercept: \u001b[0m -1.4607013095317352 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0017962642471408266,-0.002453702573612059,-0.0006453523576763175,-0.0012476692392248243,-0.0004432877962528202,-0.001266934927050461,-0.0005158913147883921,-0.0014219527592355442,0.000624353667590434,0.001861756691127019,-0.0022041779706169565,0.0012907643915619049,0.0006030329369777724,0.00020816158744324168,-0.00024942120732684156,-0.0009465744631711813,0.0011835585741138345,-0.0009630643434311739,-0.0012920716672913508,0.0014646282751669775,0.0011746803200276027,-0.00045477261729980284,-0.0011700131237265185,0.0003807170740905274,0.0012576964578288963,0.0009924252577380153,0.0017198158175984705,0.00021140712628899783,0.0005329640603528034,-0.000225357536277565,0.0002479610792089126,0.0024692819189094774,-0.0013246930490089048,-0.0004783534841007571,0.00016584604186936663,0.002115434419835019,-0.00022483283148948632,0.0019130079489666626,0.0005783641755276653,0.0012012460385434664,0.0009211272269084059,0.001266821177568292,-0.005850400802680259,-0.0016024307264219935,-0.0018580994278601718,-0.002025770214665629,-0.002104946012234815,-0.0004921046809448597,0.00035131795435848793,0.0011380223686108016,-0.00013481425518395312,-9.458221915434403e-05,-0.000823888624677448,2.8475622293272194e-05,0.0019623037821645917,-0.00037207824088826243,0.0008950719089255913,0.0008679065782451268,-0.0011720803438710434,-0.001805817841169024,0.00013582690740210603,-0.001955271996024043,0.0006287573773364991,0.0010741618907794794,0.0011687436766563914,-8.981750866588483e-05,-0.00032857635224831436,-0.0018376751687014222,-0.0017059152669754547,0.001600100389146233,0.0007034907171567461]\n",
      "\u001b[1mIntercept: \u001b[0m -1.697934112539255 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.0008253686220129691,-0.000655821843730639,-0.0017948925187689319,-0.0004626849574993811,-0.0004304314997140128,-0.0002442154477787705,0.0029026358298418556,-0.000826306447471166,0.002988466589210964,-0.0007081664687490161,-0.0054454019763322935,0.0001045747340058055,-0.00047661997717720413,-0.00040049281561095693,-0.0005097456123636352,-0.00036614801767738875,0.0008636916767399976,-0.0010690673630701225,-0.0010898148264289595,0.0018891597983698026,-0.0005197845696763309,-0.00010305325127438122,-0.00012129046900564857,-0.00011226169090909639,-0.0016156070473178422,0.00026465998218598596,0.0015230917514399264,-0.0007115861541301832,0.0027294162076255714,-0.0015358265220929226,0.0011034609789706761,-0.0004740728866215188,0.001398233319606684,-0.003530775676100733,-0.0014769277889019627,0.0016529294738479572,0.00011722908998661867,-0.0017666162797799648,-5.311605261630556e-05,-4.6234397241747476e-05,0.0021084079524434445,-0.00010860425373732971,-0.0014629754703590317,-0.0006714567755070874,-0.0008714860105239772,-0.0006803014333055337,0.0004732020983346399,-8.464855695398558e-05,0.00015272282190054894,-0.0013911176994003407,-0.0005324506856070832,-0.0016368566149557954,-0.0021743047451731902,-0.002509201461844142,-0.0023964995920839147,-0.0012152578598648408,0.000659478453799511,-0.0014568505010233675,-0.0022478044285693015,-0.0010985922459854588,0.0007961865010935286,0.003557249000772744,0.0009768923029104966,-0.0003267010872571333,-0.0010817209445412083,0.0027062515047248507,0.0016762960762482244,0.00231275126528983,0.0024591266316181326,-0.0007614252108673504,0.008207641434641493]\n",
      "\u001b[1mIntercept: \u001b[0m -4.421208093320822 \u001b[1m\n",
      "Coefficients:\u001b[0m [-0.00048103463889557466,-0.0011102494932920372,-0.0015040248537442863,-0.001217226696861051,-0.0007243556636460859,-0.0002565225049954194,-0.0019755398072887212,-0.0008617739486991589,-0.00048316807326278995,-0.0021637135263604832,-0.0010822872694385547,0.0010977148852767003,0.0003759800158688862,0.0004920804106306855,0.0008513992195705038,0.0010760263807918253,-0.0004304033809504446,-0.00052734538642983,0.000265116734837743,0.0002726733932120293,-0.00022537708199141303,-0.0015219344205044628,-0.0014576395270718124,0.0007325995724958506,0.00111274835299007,-0.0013603970659732604,0.0014011073707217456,0.00017659847288814973,-0.0010517651336949452,-0.0015463239892970003,-0.0011504228881870748,0.001436835073260731,-0.0015450767360993066,0.0012964998086499114,0.0012339370832596475,-0.0031866608270915233,0.001864186193848643,-0.0003406775724461591,0.002480067576524415,-0.000894689204123969,-0.005638010501734219,-0.0001699647432102721,-0.001446254481383448,-0.003093376582271276,0.0012000665884973453,-8.435398657065436e-05,0.0026826614716895588,0.0005940006608996922,0.0005112728887132264,0.0007858062114191421,0.0015681727114319416,-0.0003941446001944255,0.0010149643472748642,0.0016768401302089317,0.002240141323015536,-0.0008491101465906474,-0.0014872949759737444,0.00043571364649929264,0.0029416158983718264,-0.001393070328502558,0.0009846555307006166,0.00032108416698499746,0.0013139075116883993,-9.476788791184005e-05,0.0002526655707128376,0.002403106444229752,0.0013716402220373177,0.001178822817571246,0.001885473412724448,-0.00018990304676702607,-0.0028625828686898495]\n",
      "\u001b[1mIntercept: \u001b[0m -1.1435466622964001 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.0005622444145708804,-0.0012018901660025008,0.000908787483179771,0.00022520482268391126,-0.0006943411261284898,-0.0002727809706876273,0.0008750219752896772,0.00037390965424944646,-0.0017226986961359377,-2.352470808573573e-05,0.001538952459461388,-0.0001495677539501845,-0.0002108636804520567,-0.002038036780709576,0.0009114969878421772,0.00047600845300449886,0.0020747191326745858,-0.001751913388641706,-0.0016465030815888406,-0.0007535175112796374,-0.0007734490599363536,-0.00041133109760771685,-0.0006897036550074816,-0.0005365472501350199,0.0012091141388864963,-0.00041524604123079463,-0.002738386620827656,0.00025816553059718563,0.0007134175716461024,0.0011597251552308554,0.00011207153475276969,0.00014159748963226613,-0.00014799448340791985,0.0008737280197540294,0.0016814568304210147,0.0006185152004221543,0.0008651375320030968,0.001686664320435761,-0.0005528560948011561,-0.00023164261858334923,0.0018417610923145452,0.0009573502264489111,0.002338103857479223,0.0010430629002715708,0.00014147244699503592,0.00031657411602642487,0.0003037747565387729,0.00038564673794907426,-0.0005687705370195315,-0.0012275501955849473,-0.0004101295918470129,-0.00034398814801968693,-0.0006553017097991996,-0.00010954932675909914,6.741526489200065e-05,0.001318656030709188,-0.0008567996747734902,-0.0005563732368727804,-0.0017529619258005048,0.0011175133159874793,-0.0012058706687830178,-0.0018556717998271586,-0.0028615332340873206,-0.0014813614851033896,0.0007605148281915814,-0.0014374710852658706,0.0011727086229175192,-0.001784581414929314,-0.0034185931427079944,0.0005894875877303443,0.0018509024827624554]\n",
      "\u001b[1mIntercept: \u001b[0m -3.5446506845535506 \u001b[1m\n",
      "Coefficients:\u001b[0m [9.907231411269395e-05,-0.001243931165294007,-0.0012806394860880952,0.00022918350673077026,0.00020166066143116165,6.870735229327066e-05,0.0009085239380244502,-6.0060903723476056e-05,0.0010310927249155603,0.0013258971862429919,0.0011651253708444757,0.0006665771594021244,-0.002834003363685631,0.0009424955379242416,0.0004144111743947949,-0.0006313269760155108,-0.0012080382688107651,0.002501299455452109,0.0005737978526054678,-0.0003890009980668382,0.0008388397029154738,0.0026585554714434545,6.69016568779011e-05,0.0006977183278881185,0.0014136152784354791,-0.00044740747956724267,-0.0005652697015475175,0.0003287417794698117,0.001442377643310266,0.001184189463641002,-0.0007554864581538739,0.0002449549633628611,0.00010700200901131549,0.0003246644193194564,-0.0006660519365712508,0.002144901326437481,-0.0010070504507737623,0.0015065183931383182,-0.0008411469056664979,-0.0006864529931326246,0.0014377197473435172,0.0012225938235312045,-0.0030370811882848648,0.0018530896702101693,0.00028050506655555736,-0.0003495895968301899,-0.0007090988694655033,-0.00079831855347575,-0.0009542569425825506,-0.001442257022823141,-0.0005000293423332582,-0.0019131179719638753,-0.00026330811134308007,-0.0016815035697701666,-0.00041736721385903793,0.0015749162814806697,-0.0016027014037588389,-0.0011330463116213212,0.001193020431215019,-0.0012036108847131056,0.0008052008281213989,-0.0005951368040139308,-0.0034838597039432086,0.00021630677277611446,0.0016403305855519777,0.0005771672051482897,-0.0022494249364373676,0.0008175272815057022,-0.0027423139868198976,-5.419961529876222e-05,0.0015859485767809412]\n",
      "\u001b[1mIntercept: \u001b[0m -1.1290113691304218 \u001b[1m\n",
      "Coefficients:\u001b[0m [0.000532486006866998,-0.003066049229067688,0.0015992318374373764,0.001071219536459425,0.001961063738085757,0.000386203898968981,0.0010036735147898618,0.0004395549602326293,0.0013150158206618997,-0.0012311858129447784,-0.0018976647839926224,0.00020282639931951357,-0.0008537127572889921,-0.00020045607190350784,-9.621989556664695e-05,0.0011793376228353238,0.00045438913622986216,-0.0009195980567557751,0.0023406011828445723,0.0009391994217562218,0.001177438752435303,-0.00014490924924876562,0.0021758021906946572,-0.001508310408157523,0.0011376930166319432,-0.0010157876581609277,0.0005762733088051235,9.701954562673147e-05,-0.0028471550752163797,0.0007546893528532162,0.0018852003134987839,-0.00021898427899465727,0.0011658758393259915,-0.0013269248935219575,-0.0014855963630589716,-0.0035498093444528943,-0.002012913643988388,-0.0024976811053388976,-0.0024888922549369534,-0.0010997139368737552,0.0017579861088893858,-0.0007841830514214508,-0.0017684107766548006,-0.00216221264783426,-0.00206847359628821,-0.003030003597009543,-0.0019498765485423753,-0.0026920531266257175,-0.0005411205476609559,0.0005615374226945505,-0.0008252137619637872,-0.0007022828937315162,-0.0009425040751214193,-0.000290210393667357,-0.0004513805688395643,0.0014302859548335784,0.0003801795785117762,-0.000880832204266158,0.0008285739656163012,0.0017210363407684486,0.000393152817195641,0.0016833468671135054,-0.0032212361179903763,-0.0008083717133329232,0.001146157966205189,0.0017502263118000354,-0.00094090283280925,0.0001380962063737198,-0.0016752731114237473,0.00041754749275053075,0.0009164690507353348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.96423248882265\n"
     ]
    }
   ],
   "source": [
    "# Create a new run\n",
    "run = create_run(experiment_name)\n",
    "\n",
    "# instantiate the base classifier.\n",
    "lr = LogisticRegression()\n",
    "# instantiate the One Vs Rest Classifier.\n",
    "classifier = OneVsRest(classifier=lr)\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "#Cross Validator requires the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 is best practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Print the Coefficients\n",
    "# First we need to extract the best model from fit model\n",
    "\n",
    "# Get Best Model\n",
    "BestModel = fitModel.bestModel\n",
    "# Extract list of binary models\n",
    "models = BestModel.models\n",
    "for model in models:\n",
    "    print('\\033[1m' + 'Intercept: '+ '\\033[0m',model.intercept,'\\033[1m' + '\\nCoefficients:'+ '\\033[0m',model.coefficients)\n",
    "        \n",
    "# Now generate predictions on test dataset\n",
    "predictions = fitModel.transform(test)\n",
    "# And calculate the accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# And print\n",
    "print(accuracy)\n",
    "\n",
    "########### Track results in MLflow UI ################\n",
    "\n",
    "# Add tag to a run\n",
    "# Extract the name of the classifier\n",
    "classifier_name = type(classifier).__name__\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "\n",
    "# Log Model (can't do this to the client)\n",
    "# mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# Extract params of Best Model\n",
    "paramMap = BestModel.extractParamMap()\n",
    "\n",
    "# Log parameters to the client\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxIter' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Iter\", val)\n",
    "for key, val in paramMap.items():\n",
    "    if 'regParam' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Reg Param\", 5)\n",
    "\n",
    "# Log metrics to the client\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# Set a runs status to finished (best practice)\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel Weights: \u001b[0m 12023\n",
      "16.24441132637854\n"
     ]
    }
   ],
   "source": [
    "# Create a new run\n",
    "run = create_run(experiment_name)\n",
    "\n",
    "# Count how many features you have\n",
    "features = final_data.select(['features']).collect()\n",
    "features_count = len(features[0][0])\n",
    "# Then use this number to specify the layers according to best practice\n",
    "layers = [features_count, features_count+1, features_count, classes]\n",
    "# Instaniate the classifier\n",
    "classifier = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# Fit the model (this classifier doesn't have a cross validator option)\n",
    "fitModel = classifier.fit(train)\n",
    "\n",
    "# Print the model Weights\n",
    "print('\\033[1m' + \"Model Weights: \"+ '\\033[0m',fitModel.weights.size)\n",
    "   \n",
    "# Generate predictions on test dataframe\n",
    "predictions = fitModel.transform(test)\n",
    "# Calculate accuracy score\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# Print accuracy score\n",
    "print(accuracy)\n",
    "\n",
    "########### Track results in MLflow UI ################\n",
    "\n",
    "# Add tag to a run\n",
    "# Extract the name of the classifier\n",
    "classifier_name = type(classifier).__name__\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "client.set_tag(run.info.run_id,\"Model Weight\",fitModel.weights.size)\n",
    "\n",
    "# # Log Model (can't do this to the client)\n",
    "# # mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# Log metrics to the client\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# Set a runs status to finished (best practice)\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.95976154992549\n"
     ]
    }
   ],
   "source": [
    "# Create a new run\n",
    "run = create_run(experiment_name)\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = NaiveBayes()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "             .addGrid(classifier.smoothing, [0.0, 0.2, 0.4, 0.6]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)\n",
    "\n",
    "########### Track results in MLflow UI ################\n",
    "\n",
    "# Add tag to a run\n",
    "# Extract the name of the classifier\n",
    "classifier_name = type(classifier).__name__\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "\n",
    "# Log Model (can't do this to the client)\n",
    "# mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# Extract params of Best Model\n",
    "# Get Best Model\n",
    "BestModel = fitModel.bestModel\n",
    "paramMap = BestModel.extractParamMap()\n",
    "\n",
    "# Log metrics to the client\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# Set a runs status to finished (best practice)\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC cannot be used because PySpark currently only accepts binary classification data for this algorithm\n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "class_count = final_data.select(countDistinct(\"label\")).collect()\n",
    "classes = class_count[0][0]\n",
    "if classes > 2:\n",
    "    print(\"LinearSVC cannot be used because PySpark currently only accepts binary classification data for this algorithm\")\n",
    "else:\n",
    "    print(\"Your good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new run\n",
    "# run = create_run(experiment_name)\n",
    "\n",
    "# # Add parameters of your choice here:\n",
    "# classifier = LinearSVC()\n",
    "# paramGrid = (ParamGridBuilder() \\\n",
    "#              .addGrid(classifier.maxIter, [10, 15]) \\\n",
    "#              .addGrid(classifier.regParam, [0.1, 0.01]) \\\n",
    "#              .build())\n",
    "\n",
    "# #Cross Validator requires all of the following parameters:\n",
    "# crossval = CrossValidator(estimator=classifier,\n",
    "#                           estimatorParamMaps=paramGrid,\n",
    "#                           evaluator=MulticlassClassificationEvaluator(),\n",
    "#                           numFolds=2) # 3 + is best practice\n",
    "# # Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "# fitModel = crossval.fit(train)\n",
    "# BestModel = fitModel.bestModel\n",
    "\n",
    "# print('\\033[1m' + \" Coefficients\"+ '\\033[0m')\n",
    "# print(\"You should compares these relative to eachother\")\n",
    "# print(\"Coefficients: \\n\" + str(BestModel.coefficients))\n",
    "    \n",
    "# predictions = fitModel.transform(test)\n",
    "# accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "# print(accuracy)\n",
    "\n",
    "# ########### Track results in MLflow UI ################\n",
    "\n",
    "# # Add tag to a run\n",
    "# # Extract the name of the classifier\n",
    "# classifier_name = type(classifier).__name__\n",
    "# client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "# client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "# client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "\n",
    "# # Log Model (can't do this to the client)\n",
    "# # mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# # Extract params of Best Model\n",
    "# paramMap = BestModel.extractParamMap()\n",
    "\n",
    "# # Log parameters to the client\n",
    "# for key, val in paramMap.items():\n",
    "#     if 'maxIter' in key.name:\n",
    "#         client.log_param(run.info.run_id, \"Max Iter\", val)\n",
    "# for key, val in paramMap.items():\n",
    "#     if 'regParam' in key.name:\n",
    "#         client.log_param(run.info.run_id, \"Reg Param\", 5)\n",
    "\n",
    "# # Log metrics to the client\n",
    "# client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# # Set a runs status to finished (best practice)\n",
    "# client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Scores (add up to 1)\n",
      "[0.02081764 0.05118817 0.01171838 0.01483404 0.         0.\n",
      " 0.07700441 0.         0.03019932 0.         0.         0.\n",
      " 0.00824512 0.         0.         0.         0.         0.\n",
      " 0.00476809 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0178979  0.         0.         0.\n",
      " 0.01173941 0.04071074 0.02011855 0.         0.         0.04577454\n",
      " 0.         0.03032135 0.         0.06567548 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.0491326  0.11353245 0.38632183]\n",
      "37.85394932935917\n"
     ]
    }
   ],
   "source": [
    "# Create a new run\n",
    "run = create_run(experiment_name)\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = DecisionTreeClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "             .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Collect and print feature importances\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Feature Importance Scores (add up to 1)\")\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)\n",
    "\n",
    "########### Track results in MLflow UI ################\n",
    "\n",
    "# Add tag to a run\n",
    "# Extract the name of the classifier\n",
    "classifier_name = type(classifier).__name__\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "\n",
    "# Log Model (can't do this to the client)\n",
    "# mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# Extract params of Best Model\n",
    "paramMap = BestModel.extractParamMap()\n",
    "\n",
    "# Log parameters to the client\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxDepth' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Depth\", val)\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxBins' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Bins\", 5)\n",
    "\n",
    "# Log metrics to the client\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# Set a runs status to finished (best practice)\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mlflow.spark' has no attribute 'createDataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-20a8e471a35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Then zip with input_columns list and create a df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimp_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mlflow.spark' has no attribute 'createDataFrame'"
     ]
    }
   ],
   "source": [
    "# zip input_columns qith feature importance scores and create df\n",
    "\n",
    "# First convert featureimportance scores from numpy array to list\n",
    "imp_scores = []\n",
    "for x in featureImportances:\n",
    "    imp_scores.append(int(x))\n",
    "    \n",
    "# Then zip with input_columns list and create a df\n",
    "result = spark.createDataFrame(zip(input_columns,imp_scores), schema=['feature','score'])\n",
    "print(result.orderBy(result[\"score\"].desc()).show(truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Scores (add up to 1)\n",
      "[0.02452951 0.02826608 0.01846563 0.01537593 0.01019634 0.01112698\n",
      " 0.01347442 0.00746161 0.01978692 0.01599268 0.01111094 0.01149394\n",
      " 0.0089437  0.00835238 0.00674792 0.00966588 0.00735222 0.01141882\n",
      " 0.01016138 0.007549   0.00882493 0.00829091 0.00820047 0.01420782\n",
      " 0.00910477 0.00993274 0.00790388 0.00809606 0.00909602 0.00760569\n",
      " 0.00888249 0.00997186 0.0078522  0.01299461 0.01313738 0.0138498\n",
      " 0.01024035 0.01438733 0.02459726 0.00944065 0.01606044 0.01025337\n",
      " 0.02334221 0.02162931 0.01151848 0.01102211 0.01304802 0.01362931\n",
      " 0.01648225 0.01248605 0.01394351 0.01987286 0.01661394 0.01425151\n",
      " 0.01628015 0.0116149  0.00852716 0.01047246 0.00782175 0.01198437\n",
      " 0.00956313 0.01325482 0.01428684 0.00548118 0.00733403 0.0111689\n",
      " 0.00774623 0.01183569 0.04886875 0.03009204 0.08542476]\n",
      "45.603576751117735\n"
     ]
    }
   ],
   "source": [
    "# Create a new run\n",
    "run = create_run(experiment_name)\n",
    "\n",
    "# Add parameters of your choice here:\n",
    "classifier = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "               .addGrid(classifier.maxDepth, [2, 5, 10])\n",
    "#                                .addGrid(classifier.maxBins, [5, 10, 20])\n",
    "#                                .addGrid(classifier.numTrees, [5, 20, 50])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "# Retrieve best model from cross val\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Feature Importance Scores (add up to 1)\")\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(featureImportances)\n",
    "\n",
    "predictions = fitModel.transform(test)\n",
    "\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)\n",
    "\n",
    "########### Track results in MLflow UI ################\n",
    "\n",
    "# Add tag to a run\n",
    "# Extract the name of the classifier\n",
    "classifier_name = type(classifier).__name__\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "\n",
    "# Log Model (can't do this to the client)\n",
    "# mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# Extract params of Best Model\n",
    "paramMap = BestModel.extractParamMap()\n",
    "\n",
    "# Log parameters to the client\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxDepth' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Depth\", val)\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxBins' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Bins\", 5)\n",
    "\n",
    "# Log metrics to the client\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# Set a runs status to finished (best practice)\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o88796.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25167.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25167.0 (TID 28318) (192.168.29.100 executor driver): java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:177)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:174)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:162)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:160)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:219)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:219)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1207)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2296)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2297)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$1(RDD.scala:1209)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.aggregate(RDD.scala:1202)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:125)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.boost(GradientBoostedTrees.scala:333)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.run(GradientBoostedTrees.scala:61)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$1(GBTClassifier.scala:210)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:171)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:59)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat jdk.internal.reflect.GeneratedMethodAccessor321.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:177)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:174)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:162)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:160)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:219)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:219)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1207)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2296)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-12e97fdd1d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Fit Model: Run cross-validation, and choose the best set of parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mfitModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mBestModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parallelFitTasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnFolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcollectSubModelsParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/tuning.py\u001b[0m in \u001b[0;36msingleTask\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msingleTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;31m# TODO: duplicate evaluator to take extra params from input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#  Note: Supporting tuning params in evaluator need update method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No models remaining.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitSingleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfitSingleModel\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfitSingleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparamMaps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_FitMultipleIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitSingleModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamMaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o88796.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 25167.0 failed 1 times, most recent failure: Lost task 0.0 in stage 25167.0 (TID 28318) (192.168.29.100 executor driver): java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:177)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:174)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:162)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:160)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:219)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:219)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1207)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2296)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2297)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$1(RDD.scala:1209)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.aggregate(RDD.scala:1202)\n\tat org.apache.spark.ml.tree.impl.DecisionTreeMetadata$.buildMetadata(DecisionTreeMetadata.scala:125)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.boost(GradientBoostedTrees.scala:333)\n\tat org.apache.spark.ml.tree.impl.GradientBoostedTrees$.run(GradientBoostedTrees.scala:61)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$1(GBTClassifier.scala:210)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:171)\n\tat org.apache.spark.ml.classification.GBTClassifier.train(GBTClassifier.scala:59)\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:151)\n\tat jdk.internal.reflect.GeneratedMethodAccessor321.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.IllegalArgumentException: requirement failed: GBTClassifier was given dataset with invalid label 2.0.  Labels must be in {0,1}; note that GBTClassifier currently only supports binary classification.\n\tat scala.Predef$.require(Predef.scala:281)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2(GBTClassifier.scala:177)\n\tat org.apache.spark.ml.classification.GBTClassifier.$anonfun$train$2$adapted(GBTClassifier.scala:174)\n\tat org.apache.spark.ml.PredictorParams.$anonfun$extractInstances$2(Predictor.scala:96)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:459)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:162)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:160)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:219)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:219)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1429)\n\tat org.apache.spark.rdd.RDD.$anonfun$aggregate$2(RDD.scala:1207)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$6(SparkContext.scala:2296)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Create a new run\n",
    "run = create_run(experiment_name)\n",
    "    \n",
    "# Add parameters of your choice here:\n",
    "classifier = GBTClassifier()\n",
    "\n",
    "paramGrid = (ParamGridBuilder() \\\n",
    "#                              .addGrid(classifier.maxDepth, [2, 5, 10, 20, 30]) \\\n",
    "#                              .addGrid(classifier.maxBins, [10, 20, 40, 80, 100]) \\\n",
    "             .addGrid(classifier.maxIter, [10, 15,50])\n",
    "             .build())\n",
    "\n",
    "#Cross Validator requires all of the following parameters:\n",
    "crossval = CrossValidator(estimator=classifier,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "                          numFolds=2) # 3 + is best practice\n",
    "\n",
    "# Fit Model: Run cross-validation, and choose the best set of parameters.\n",
    "fitModel = crossval.fit(train)\n",
    "\n",
    "BestModel = fitModel.bestModel\n",
    "print(\"Feature Importance Scores (add up to 1)\")\n",
    "featureImportances = BestModel.featureImportances.toArray()\n",
    "print(featureImportances)\n",
    "    \n",
    "predictions = fitModel.transform(test)\n",
    "accuracy = (MC_evaluator.evaluate(predictions))*100\n",
    "print(accuracy)\n",
    "\n",
    "########### Track results in MLflow UI ################\n",
    "\n",
    "# Add tag to a run\n",
    "# Extract the name of the classifier\n",
    "classifier_name = type(classifier).__name__\n",
    "client.set_tag(run.info.run_id, \"Algorithm\", classifier_name) \n",
    "client.set_tag(run.info.run_id,\"Random Seed\",seed)\n",
    "client.set_tag(run.info.run_id,\"Train Perct\",train_val)\n",
    "\n",
    "# Log Model (can't do this to the client)\n",
    "# mlflow.spark.log_model(fitModel, \"model\")\n",
    "\n",
    "# Extract params of Best Model\n",
    "paramMap = BestModel.extractParamMap()\n",
    "\n",
    "# Log parameters to the client\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxDepth' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Depth\", val)\n",
    "for key, val in paramMap.items():\n",
    "    if 'maxBins' in key.name:\n",
    "        client.log_param(run.info.run_id, \"Max Bins\", 5)\n",
    "\n",
    "# Log metrics to the client\n",
    "client.log_metric(run.info.run_id, \"Accuracy\", accuracy)\n",
    "\n",
    "# Set a runs status to finished (best practice)\n",
    "client.set_terminated(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
